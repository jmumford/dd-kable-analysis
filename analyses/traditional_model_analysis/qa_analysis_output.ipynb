{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import plotting\n",
    "\n",
    "from dd_kable_analysis.config_loader import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697d939",
   "metadata": {},
   "source": [
    "# Basic QA for analysis completion of the traditional model analysis\n",
    "\n",
    "## Load Configuration and Paths for QA Output\n",
    "Import required libraries, load configuration, and define output/log directories for QA checks.\n",
    "\n",
    "### Note: After running this post-analysis, the log files will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config()\n",
    "output_root = Path(cfg.output_root) / 'traditional_model' / 'first_level'\n",
    "logs_dir = Path(\n",
    "    '/oak/stanford/groups/russpold/users/buckholtz/DD_Kable/scripts/dd-kable-analysis/logs'\n",
    ")\n",
    "\n",
    "print(output_root)\n",
    "print(logs_dir)\n",
    "\n",
    "# Note: log files will be deleted after they are checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2660312",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = 'dmp0011'\n",
    "run = '1'\n",
    "\n",
    "output_dir = Path(\n",
    "    f'/oak/stanford/groups/russpold/users/buckholtz/DD_Kable/derivatives/analysis_output/traditional_model/first_level/sub-{sub_id}/contrast_estimates'\n",
    ")\n",
    "\n",
    "# Define consistent z-slice coordinates\n",
    "z_coords = np.linspace(-40, 70, 8)\n",
    "\n",
    "# Check ll - ss contrast\n",
    "ll_minus_ss = (\n",
    "    output_dir\n",
    "    / f'sub-{sub_id}_ses-scan1_task-itc_run-{run}_contrast-ll_minus_ss_output-effectsize.nii.gz'\n",
    ")\n",
    "plotting.plot_stat_map(\n",
    "    ll_minus_ss,\n",
    "    display_mode='z',\n",
    "    cut_coords=z_coords,\n",
    "    title='Larger Later - Smaller Sooner',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Batch-run verification (run after jobs finish) ---\n",
    "# (logs may have been deleted)\n",
    "good_subs = pd.read_csv(cfg.subject_lists / 'initial_qa_pass_subjects_runs.csv')\n",
    "\n",
    "output_root = Path(cfg.output_root) / 'traditional_model' / 'first_level'\n",
    "logs_dir = Path(\n",
    "    '/oak/stanford/groups/russpold/users/buckholtz/DD_Kable/scripts/dd-kable-analysis/logs',\n",
    ")\n",
    "\n",
    "success_pattern = re.compile(\n",
    "    r'Analysis complete for sub-(?P<sub_id>\\w+), run (?P<run>\\d+)'\n",
    "    r'|SUCCESS: Analysis completed for sub-(?P<sub_id2>\\w+), run (?P<run2>\\d+)'\n",
    ")\n",
    "\n",
    "success_pairs = set()\n",
    "for log_file in sorted(logs_dir.glob('traditional_model_*.out')):\n",
    "    try:\n",
    "        text = log_file.read_text()\n",
    "    except Exception:\n",
    "        continue\n",
    "    for match in success_pattern.finditer(text):\n",
    "        sub_id = match.group('sub_id') or match.group('sub_id2')\n",
    "        run = match.group('run') or match.group('run2')\n",
    "        success_pairs.add((sub_id, int(run)))\n",
    "\n",
    "\n",
    "def count_maps(sub_id: str, run: int):\n",
    "    out_dir = output_root / f'sub-{sub_id}' / 'contrast_estimates'\n",
    "    if not out_dir.exists():\n",
    "        return 0, out_dir\n",
    "    files = list(\n",
    "        out_dir.glob(\n",
    "            f'sub-{sub_id}_ses-*_task-*_run-{run}_contrast-*_output-effectsize.nii.gz',\n",
    "        )\n",
    "    )\n",
    "    return len(files), out_dir\n",
    "\n",
    "\n",
    "rows = []\n",
    "for _, row in good_subs.iterrows():\n",
    "    sub_id = row['sub_id']\n",
    "    run = int(row['run'])\n",
    "    n_maps, out_dir = count_maps(sub_id, run)\n",
    "    rows.append(\n",
    "        {\n",
    "            'sub_id': sub_id,\n",
    "            'run': run,\n",
    "            'output_dir': str(out_dir),\n",
    "            'n_maps': n_maps,\n",
    "            'has_maps': n_maps > 0,\n",
    "            'log_success': (sub_id, run) in success_pairs,\n",
    "        }\n",
    "    )\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "summary['status'] = summary.apply(\n",
    "    lambda r: 'ok'\n",
    "    if r.has_maps and r.log_success\n",
    "    else 'missing'\n",
    "    if not r.has_maps\n",
    "    else 'no_log_success',\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(summary['status'].value_counts())\n",
    "\n",
    "failed = summary[summary['status'] != 'ok']\n",
    "failed.head()\n",
    "\n",
    "err_logs = [p for p in logs_dir.glob('traditional_model_*.err') if p.stat().st_size > 0]\n",
    "print(f'Non-empty error logs: {len(err_logs)}')\n",
    "err_logs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Batch-run verification (run after jobs finish) ---\n",
    "# (logs may have been deleted)\n",
    "good_subs = pd.read_csv(cfg.subject_lists / 'initial_qa_pass_subjects_runs.csv')\n",
    "\n",
    "output_root = Path(cfg.output_root) / 'traditional_model' / 'first_level'\n",
    "logs_dir = Path(\n",
    "    '/oak/stanford/groups/russpold/users/buckholtz/DD_Kable/scripts/dd-kable-analysis/logs',\n",
    ")\n",
    "\n",
    "success_pattern = re.compile(\n",
    "    r'Analysis complete for sub-(?P<sub_id>\\w+), run (?P<run>\\d+)'\n",
    "    r'|SUCCESS: Analysis completed for sub-(?P<sub_id2>\\w+), run (?P<run2>\\d+)'\n",
    ")\n",
    "\n",
    "success_pairs = set()\n",
    "for log_file in sorted(logs_dir.glob('traditional_model_*.out')):\n",
    "    try:\n",
    "        text = log_file.read_text()\n",
    "    except Exception:\n",
    "        continue\n",
    "    for match in success_pattern.finditer(text):\n",
    "        sub_id = match.group('sub_id') or match.group('sub_id2')\n",
    "        run = match.group('run') or match.group('run2')\n",
    "        success_pairs.add((sub_id, int(run)))\n",
    "\n",
    "\n",
    "def count_maps(sub_id: str, run: int):\n",
    "    out_dir = output_root / f'sub-{sub_id}' / 'contrast_estimates'\n",
    "    if not out_dir.exists():\n",
    "        return 0, out_dir\n",
    "    files = list(\n",
    "        out_dir.glob(\n",
    "            f'sub-{sub_id}_ses-*_task-*_run-{run}_contrast-*_output-effectsize.nii.gz',\n",
    "        )\n",
    "    )\n",
    "    return len(files), out_dir\n",
    "\n",
    "\n",
    "rows = []\n",
    "for _, row in good_subs.iterrows():\n",
    "    sub_id = row['sub_id']\n",
    "    run = int(row['run'])\n",
    "    n_maps, out_dir = count_maps(sub_id, run)\n",
    "    rows.append(\n",
    "        {\n",
    "            'sub_id': sub_id,\n",
    "            'run': run,\n",
    "            'output_dir': str(out_dir),\n",
    "            'n_maps': n_maps,\n",
    "            'has_maps': n_maps > 0,\n",
    "            'log_success': (sub_id, run) in success_pairs,\n",
    "        }\n",
    "    )\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "summary['status'] = summary.apply(\n",
    "    lambda r: 'ok'\n",
    "    if r.has_maps and r.log_success\n",
    "    else 'missing'\n",
    "    if not r.has_maps\n",
    "    else 'no_log_success',\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(summary['status'].value_counts())\n",
    "\n",
    "failed = summary[summary['status'] != 'ok']\n",
    "failed.head()\n",
    "\n",
    "err_logs = [p for p in logs_dir.glob('traditional_model_*.err') if p.stat().st_size > 0]\n",
    "print(f'Non-empty error logs: {len(err_logs)}')\n",
    "err_logs[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
